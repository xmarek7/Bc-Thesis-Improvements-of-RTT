%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% I, the copyright holder of this work, release this work into the
%% public domain. This applies worldwide. In some countries this may
%% not be legally possible; if so: I grant anyone the right to use
%% this work for any purpose, without any conditions, unless such
%% conditions are required by law.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[
  digital,     %% The `digital` option enables the default options for the
               %% digital version of a documeant. Replace with `printed`
               %% to enable the default options for the printed version
               %% of a document.
%%  color,       %% Uncomment these lines (by removing the %% at the
%%               %% beginning) to use color in the printed version of your
%%               %% document
  oneside,     %% The `oneside` option enables one-sided typesetting,
               %% which is preferred if you are only going to submit a
               %% digital version of your thesis. Replace with `twoside`
               %% for double-sided typesetting if you are planning to
               %% also print your thesis. For double-sided typesetting,
               %% use at least 120 g/m² paper to prevent show-through.
  nosansbold,  %% The `nosansbold` option prevents the use of the
               %% sans-serif type face for bold text. Replace with
               %% `sansbold` to use sans-serif type face for bold text.
  nocolorbold, %% The `nocolorbold` option disables the usage of the
               %% blue color for bold text, instead using black. Replace
               %% with `colorbold` to use blue for bold text.
  nolof,         %% The `lof` option prints the List of Figures. Replace
               %% with `nolof` to hide the List of Figures.
  nolot,         %% The `lot` option prints the List of Tables. Replace
               %% with `nolot` to hide the List of Tables.
]{fithesis4}
%% The following section sets up the locales used in the thesis.
\usepackage[resetfonts]{cmap} %% We need to load the T2A font encoding
\usepackage[T1,T2A]{fontenc}  %% to use the Cyrillic fonts with Russian texts.
\usepackage[
  main=english, %% By using `czech` or `slovak` as the main locale
                %% instead of `english`, you can typeset the thesis
                %% in either Czech or Slovak, respectively.
  english, german, russian, czech, slovak %% The additional keys allow
]{babel}        %% foreign texts to be typeset as follows:
%%
%%   \begin{otherlanguage}{german}  ... \end{otherlanguage}
%%   \begin{otherlanguage}{russian} ... \end{otherlanguage}
%%   \begin{otherlanguage}{czech}   ... \end{otherlanguage}
%%   \begin{otherlanguage}{slovak}  ... \end{otherlanguage}
%%
%% For non-Latin scripts, it may be necessary to load additional
%% fonts:
\usepackage{paratype}
\usepackage{todonotes}
\setuptodonotes{inline}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{array}
\usepackage{longtable}
\def\textrussian#1{{\usefont{T2A}{PTSerif-TLF}{m}{rm}#1}}
%%
%% The following section sets up the metadata of the thesis.
\thesissetup{
    date        = \the\year/\the\month/\the\day,
    university  = mu,
    faculty     = fi,
    type        = bc,
    department  = Department of Computer Systems and Communications,
    author      = Tomáš Marek,
    gender      = m,
    advisor     = {Ing. Milan Brož, Ph.D.},
    title       = {Improvements to the Randomness Testing Toolkit},
    TeXtitle    = {Improvements to the Randomness Testing Toolkit},
    keywords    = {keyword1, keyword2, ...},
    TeXkeywords = {keyword1, keyword2, \ldots},
    abstract    = {%
      This is the abstract of my thesis, which can

      span multiple paragraphs.
    },
    thanks      = {%
      These are the acknowledgements for my thesis, which can

      span multiple paragraphs.
    },
    bib         = bibliography.bib,
    %% Remove the following line to use the JVS 2018 faculty logo.
    facultyLogo = fithesis-fi,
}
\usepackage{makeidx}      %% The `makeidx` package contains
\makeindex                %% helper commands for index typesetting.
%% These additional packages are used within the document:
\usepackage{paralist} %% Compact list environments
\usepackage{amsmath}  %% Mathematics
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{url}      %% Hyperlinks
\usepackage{markdown} %% Lightweight markup
\usepackage{listings} %% Source code highlighting
\lstset{
  basicstyle      = \ttfamily,
  identifierstyle = \color{black},
  keywordstyle    = \color{blue},
  keywordstyle    = {[2]\color{cyan}},
  keywordstyle    = {[3]\color{olive}},
  stringstyle     = \color{teal},
  commentstyle    = \itshape\color{magenta},
  breaklines      = true,
}
\usepackage{floatrow} %% Putting captions above tables
\floatsetup[table]{capposition=top}
\usepackage[babel]{csquotes} %% Context-sensitive quotation marks
\begin{document}
%% The \chapter* command can be used to produce unnumbered chapters:
\chapter*{Introduction}
%% Unlike \chapter, \chapter* does not update the headings and does not
%% enter the chapter to the table of contents. I we want correct
%% headings and a table of contents entry, we must add them manually:
\markright{\textsc{Introduction}}
\addcontentsline{toc}{chapter}{Introduction}
\todo{To be done, now it is only a collection of ideas.}

%Random number generators are tested by taking an output sample. This 

The desired properties of random sequence are \emph{uniformity} (for each bit the probability for both zero and one are exactly $1/2$), \emph{independence} (none of the bits is influenced by any other bit) and \emph{unpredictability} (it is impossible to predict next bit by obtaining any number of previous bits). \cite[p. 1-1]{nist_special}

% RANDOMNESS TESTING - 'theoretical' chapter

\chapter{Randomness testing}

Goal of this chapter is to provide overview of randomness testing process and to explain all used terms. Explanations of both one and two level tests are accompanied by example applications.

\section{Overview / Introduction} \label{chap:rand-intro}

%Testing a sequence (define) (tu01guide - 1, tu01paper - 3, 17), required properties(nistspecial 1-1, 1-3 )

During a randomness test a \emph{random sequence} is tested. In this document, a random sequence is a finite sequence of zero and one bits, which was generated by a tested random number generator.  \cite[p. 1-1]{nist_special} 

%Null/alternative hypothesis (tu01paper - 3, možná učebnice)
%Randomness testing as statistical testing (tu01guide - 2)

Randomness test is a form of \emph{empirical statistical test}, where we test our assumption about the tested data - the \emph{null hypothesis} ($H_0$). During the randomness test it states that the sequence is \emph{random}. Associated with the null-hypothesis is the \emph{alternative hypothesis} ($H_1$), which states that the sequence is \emph{non-random}. Goal of the test is to search for evidence against the null-hypothesis. \cite[p. 2]{tu01_guide}

%Idea of testing – extremeness of a sample ? (nistspecial - 1-3+)

%result (accept, reject, Type I/II error) (nistspecial - 1-3+, učebnice 416)

The result of the test is either that we \emph{accept} the null hypothesis (the sequence is considered random), or that we \emph{reject} the null-hypothesis (and accept the alternative hypothesis - the sequence is considered non-random). We reject the null hypothesis when the evidence found against the null-hypothesis is strong enough, otherwise we accept it. Based on the true situation of null hypothesis, four situations depicted in Table \ref{tab:type_errors} may occur. \cite[p. 417]{basic_practice}

\begin{table}
  \begin{tabularx}{0.7\textwidth}{l|c|c}
    %\toprule
    TRUE  & \multicolumn{2}{c}{TEST CONCLUSION}\\
    SITUATION &Accept $H_0$ & Reject $H_0$\\
    \midrule
    $H_0$ is True &  No error & Type I error  \\
    $H_0$ is False & Type II error & No error \\
    %\bottomrule
  \end{tabularx}
  \caption{Possible outcomes when assessing the result of statistical test.}
  \label{tab:type_errors}
\end{table}

\section{Single-level testing} \label{chap:rand-single}
%significance level (tu01 paper 5-8, nistspecial 1-3+, rec for stat testing 5, učebnice)

A single-level test examines the random sequence directly (compare with \ref{chap:rand-two_level}). Before the test user must choose a \emph{significance level}, which determines how strong the found evidence has to be to reject the null-hypothesis. The test yields a \emph{p-value}, which is used to make the accept or reject the null-hypothesis.

The \emph{significance level} ($\alpha$) is crucial to assessing the test result and must be set before the test. The $\alpha$ is equal to probability of Type I Error. Usual values are $\alpha = 0.05$ or $\alpha = 0.01$ \cite[p. 390]{basic_practice}, for use in testing of cryptographic random number generators lower values may be chosen. \cite[p. 1-4]{nist_special} The lower $\alpha$ is set, the stronger the found evidence has to be to reject the null hypothesis. %(cite? derived from nistspecial 1-4)

%Test statistic (= function, known distribution), sample (tu01 paper 4+)

The randomness test is defined by a \emph{test statistic} $Y$, which is a function of a finite bit sequence. Distribution of its values under the null hypothesis must be known (or at least approximated). The value of the test statistic ($y$) is computed for the tested random sequence. Each test statistic searches for presence or absence of some "pattern" in the sequence, which would show the non-randomness of the sequence. There is infinite number of possible test statistics. \cite[p. 4]{tu01_paper}

%p-value (one, two tailed, how extremeness is set) (nist-opt 5, nist-special 1-4,rec for stat testing 5)

The \emph{p-value} is the probability of the test statistic $Y$ taking value at least as extreme as the observed $y$, assuming that the null hypothesis is true. In randomness testing it is equal to the probability that \emph{perfect random number generator} would generate less random sequence. The smaller is the p-value, the stronger is the found evidence against the null-hypothesis. \cite[p. 386]{basic_practice} The p-value is calculated based on the observed $y$.



\subsection{Result interpretation} \label{chap:rand-interpretation}
%interpratation (učebnice 380-400)

Decision about the test result is based on the computed \emph{p-value}. If the p-value is lower than the $\alpha$, we \emph{reject the null hypothesis} (and accept the alternative hypothesis), because strong enough evidence against null hypothesis was found. If the p-value is greater than or equal to the $\alpha$, we \emph{accept the null hypothesis}, because the evidence against the randomness was too weak. \cite[p. 390]{basic_practice} It is sometimes recommended to report the \emph{p-value} as well instead of accept/reject only, as it yields more information. \cite[p. 90]{tu01_guide}

% TODO: note on moving alpha, for one alpha fail, for other pass

The p-values close to $\alpha$ can be considered \emph{suspicious}, because they do not clearly indicate rejection. Further testing of the random number generator on \emph{other} random sequences is then in place to search for further evidence. \cite[p. 5]{tu01_paper} The reason is that \emph{randomness} is a probabilistic property, therefore even the perfect random number generator may generate a nonrandom sequence with low p-value (although it is very unlikely). The further evidence is used to differentiate between the bad generator generating a non-random sequence systematicaly and the good generator generating non-random sequence 'by chance'. \cite[p. 90]{tu01_guide}

%example
\subsection{Example} \label{chap:rand-example}

To demonstrate how a single randomness test is made, the Frequency (Monobit) Test from NIST STS battery was chosen. \cite[p. 2-2]{nist_special} This test is based on testing the fraction of zeroes and ones within the sequence. For a random sequence with length $n$ the  count of ones (and zeroes) is expected to be around $n/2$ (the most probable values are close to $n/2$). 

For the Monobit test it is recommended that the tested sequence has at least 100 bits. The test statistic $S_{obs}$ of the Monobit test is defined as \[S_{obs} = \dfrac{|\#_1 - \#_0|}{\sqrt{n}}\] where $\#_1$ is count of ones in the tested sequence (similarly for zeroes) and $n$ is length of of the tested sequence. Under the null hypothesis, the reference distribution of $S_{obs}$ is half normal (for large $n$). The p-vaue is computed as \[ p = erfc(\dfrac{S_{obs}}{\sqrt{2}}) \] where $erfc$ is the \emph{complementary error function} used to calculate probabilities in normal distribution.

 Let
\[\begin{split}
    \epsilon = 10011001010010000010001001011001101100001101000111\\10101001010010010011100111001100110010010100111011
\end{split}\]
 be the tested sequence. The test statistic for this sequence is 
 \[S_{obs} = \dfrac{|46 - 54|}{\sqrt{100}}\ = \dfrac{|-8|}{10} = 0.8\]
 and the p-value (visualised at Figure \ref{fig:example}) is 
 \[p = erfc\biggl(\dfrac{0.8}{\sqrt{2}}\biggr) \approx 0.423\]

To interpret the test, we compare the computed \emph{p-value} to the chosen $\alpha$. The $\emph{p-value} \approx 0.423$ is greater than both usual $\alpha = 0.05$ and $\alpha = 0.01$, therefore we accept the null hypothesis for both \emph{significance levels} and the sequence $\epsilon$ is considered random.

\begin{figure}
  \begin{center}
    %% minimus is about 100 pixels per 1 centimeter or 300 pixels per 1 inch.
    %% The optimum is about 250 pixels per 1 centimeter 
    \includegraphics[width=8cm]{figures/test_example.png}
  \end{center}
  \caption{Visualization of example p-value for test statistic value $y = 0.8$}
  \label{fig:example}
\end{figure}

% two-level (tu01guide 88, tu01paper 5-8, correcting_dieharder 14)
\section{Two-level testing} \label{chap:rand-two_level}

% two-level motivation (tu01_paper 5-8)
The \emph{two-level test} is done by repeating the single-level test $n$ times. The important part is comparing the distribution of produced p-values to the expected distribution. The two-level test allows the random sequence to be examined both locally and globally, while the single-level test examines the sequence only on the global level. This may lead to discovering local patterns, which cancel out on the global level. \cite[p. 7]{tu01_paper}

To apply the two-level test the tested sequence is split into $n$ equal-length disjoint subsequences. The same single-level test is applied to each of the subsequences (as described in Section \ref{chap:rand-single}) and its \emph{p-values} are collected, resulting in set of $n$ \emph{p-values}\footnote{Note that the p-values are not subject to accept/reject decision.}. The tests are called \emph{first-level tests} and the p-values are called \emph{first-level p-values}. Under the null-hypothesis, the first-level p-values of a given test statistic are uniformly distributed over the interval $(0,1]$. \cite[p. 14]{bad_day} 

% GOF  - 1
The crucial part of two-level test is examining the distribution of \emph{observed first-level p-values}. Usually, the \emph{goodness-of-fit} (GOF) tests are applied as the \emph{second-level test}. \cite[p. 6]{tu01_paper} GOF tests are a family of methods used for examining how well a data sample fits given distribution. \cite[p. 1]{GOF-techniques} The most used GOF tests in randomness testing are the $\chi^2$ (chi-squared) and Kolmogorov-Smirnov test, another notable tests are the Anderson-Darling and Cramér-von-Mises test. \cite[p. 14]{bad_day}

The second-level test is defined by a test statistic $Y$, which is a function of the first-level p-values. Test statistic value ($y$) is calculated from the observed \emph{first-level p-values} and then the \emph{second-level p-value} is calculated from $y$. At last, the second-level p-value is interpreted as in one-level test (as described in Subsection \ref{chap:rand-interpretation}). 

% ratio of passed sequences
Alternatively, a \emph{proportion of subsequences passing the first-level test} is used to examine the fist-level p-values uniformity. Under the null-hypothesis, it is expected for $n\cdot\alpha$ subsequences to \emph{be rejected} (i.e. to have p-value $< \alpha$) by the first-level test (be a subject to Type I Error). The ratio of sequences passing the first-level test is expected to be around $1-\alpha$, different ratio indicates non-uniformity of observed first-level p-values. \cite[p. 4-2]{nist_special} No p-value is reported in this case, only the ratio.

% GOF comparison?: (rec_for_stat 6)

% KS - description - (para and non para - 171)
\subsection{Kolmogorov-Smirnov test}
The one-sample Kolmogorov-Smirnov (KS) test is used in randomness testing to compare the observed first-level p-values to the uniform distribution. The Kolmogorov-Smirnov test is built on comparing the cumulative distribution function (CDF)\footnote{For a given distribution and value $x$, the CDF returns the probability of drawing a value less than or equal to $x$.} of the expected distribution and the empirical cumulative distribution function (eCDF)\footnote{For a set of observed data and value $x$, the eCDF returns the probability of drawing a value less than or equal to $x$.} of the observed samples. %cdf - nist_special 1-5 

In first variant, two test statistics are calculated. The test statistic $D^+$ ($D^-$) is the maximal vertical distance between CDF and eCDF above (under) the CDF. In second variant, only the test statistic $D$ (maximal vertical distance between CDF and eCDF) is measured. Formally, the test statistics are defined as
\[\begin{split}
    &D^+ = sup_x\{F_n(x) - F(x)\}\\
    &D^- = sup_x\{F(x) - F_n(x)\}\\
    &D \:\:\:= sup_x\{|F_n(x) - F(x)|\} = max(D^+, D^-)
\end{split}
\] where $F(x)$ is the CDF and $F_n(x)$ is the  eCDF \cite[p. 100]{GOF-techniques}.


\begin{figure}
  \begin{center}
    %% minimus is about 100 pixels per 1 centimeter or 300 pixels per 1 inch.
    %% The optimum is about 250 pixels per 1 centimeter 
    \includegraphics[width=9cm]{figures/ks_d.png}
  \end{center}
  \caption{Visualization of Kolmogorov-Smirnov test statistics for expected uniform distribution and observed data sample.}
  \label{fig:ks_d}
\end{figure}

% $\chi^2$ description (GOF - 100)
\subsection{Chi-squared test}

The Pearson's $\chi^2$ test is used to find statistically significant difference between frequencies of categories in two sets of categorical data. The first-level p-values are split into $k$ equal-width bins (categories) and their respective frequencies are counted. The counted frequencies are compared to the expected frequencies.

For data with $k$ categories the test statistic $\chi^2$ is defined as \[\chi^2 = \sum_{i=1}^{k} \dfrac{(x_i - m_i)^2}{m_i} \]
where $x_i$ is the observed frequency in $i$-th category and $m_i$ is the expected frequency in $i$-th category. For first-level p-values, the expected frequency is equal in each interval. For a correct test the expected frequency in each category must be at least five. \cite[p. 171]{stat-procedures}

% Two-level example
\subsection{Example}

In the two-level test example, I will test one sequence using both one and two-level tests to demonstrate the difference between them. First, the sequence is tested using the one-level Frequency (Monobit) test from NIST STS battery.\cite[p. 2-2]{nist_special} Then the same sequence is assessed by the two-level test using the Frequency test as the first-level test and KS and $\chi^2$ tests as second-level test. Let
\[\begin{split}
    \epsilon =\:15\: &* (100\:consecutitive\:zeroes) + \\
    15\:&*\:(100\:alternating\:ones\:and\:zeroes) + \\
    5\:&*\:(55\:zeroes\:and\:45\:ones)\:+\:\\
    15\:&*\:(100\:consecutive\:ones)
\end{split}\]
be the tested sequence. 

Result of the one-level Frequency test for the sequence $\epsilon$ is p-value $\approx$ 0.479. The null hypothesis is accepted for both $\alpha = 0.01$ and $\alpha = 0.05$ and the sequence $\epsilon$ is considered random. This sequence however clearly contains a pattern, therefore the probability of it being generated by a perfect random number generator is very low.

For the two-level test, the sequence $\epsilon$ is split into $n=50$  disjoint 100 bit long subseqeunces. The Monobit test is applied on each subsequence resulting in set of first-level p-values shown in Table \ref{tab:first_pvalues}.

\begin{table}
  \begin{tabularx}{0.4\textwidth}{ll}
    \toprule
    p-value & occurrences  \\
    \midrule
    $1.52 \cdot 10^{-23}$ & $30$\\
    $0.31$ & $5$\\
    $1.0$ & $15$\\
    \bottomrule
  \end{tabularx}
  \caption{First-level p-values produced by Monobit test}
  \label{tab:first_pvalues}
\end{table}

Last step is to apply the goodness-of-fit tests. The first applied test is the Pearson's $\chi^2$ test with $k=10$ (number of categories), the expected frequency of p-values in each category is five. The statistic of the test is
\[\chi^2 = \sum_{i=1}^{10} \dfrac{(x_i - 5)^2}{5} = 180 \]
and the p-value of this test is $p\approx5.06\cdot10^{-34}$. The null hypothesis is rejected for both $\alpha = 0.01$ and $\alpha = 0.05$. 

Next, the Kolmogorov-Smirnov test is applied. The eCDF is calculated and then the D statistic is computed. The statistic is $D = 0.6$ and results in p-value $\approx 9.63\cdot10^{-18}$. Again, the null-hypothesis is rejected for both $\alpha = 0.01$ and $\alpha = 0.05$ and the sequence is considered non-random.

\begin{figure}
  \begin{center}
    %% minimus is about 100 pixels per 1 centimeter or 300 pixels per 1 inch.
    %% The optimum is about 250 pixels per 1 centimeter 
    \includegraphics[width=12.5cm]{figures/two_example.png}
  \end{center}
  \caption{Visualisations for $\chi^2$ and KS tests for two-level test example.}
  \label{fig:two_example}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%
%AVAILABLE SOLUTIONS
%%%%%%%%%%%%%%%%%%%%%

\chapter{Programms for randomness tesing}
In this chapter, available programms for randomness testing are presented. First section describes \emph{statistical testing batteries} (later often referred to as batteries).  The second section shows \emph{randomness testing toolkits}, which encompass several batteries together. Overview of setup and output is given in both sections.

\section{Statistical testing batteries} \label{chap:sols-batteries}
%battery, individual test - mapping to test statistic
%Mention overflow detection
%If there are any problems with the battery (e.g. tests which read different amount of data from DieHarder). -
%how batteries interpret results (first/second level, more statistics)
%strong and weak things 
%describe output / image
%General description of battery - set of tests, choose test by ID, set tested file \\
%individual test - smallest executable part, possibly more test statistics, setting of the test(ntup, bitw...), data consumption (fixed vs set by user), number of first levels, return-first level pvalues, second-level p-value,


% (Obratil 2, tu01 guide 5)

\emph{Statistical testing battery (suite)} is a set of randomness tests with predefined parameters that allows the user to conveniently apply randomness tests. \cite[p. 5]{tu01_guide} Because all of the batteries share significant similarities, an \emph{abstract battery} is presented to demonstrate the principles. Then, each battery is presented in more detail, mapping its features to the \emph{abstract battery}. The described batteries are Dieharder, NISTS STS, several batteries from TestU01, FIPS ans BSI.

% TODO: data consumption of tests
An \emph{abstract battery} consist of $n$ individual tests, which are distinguished by \emph{test IDs}. Usually, one individual test maps to one two-level test. Some individual tests consist of more \emph{subtests}, which are all executed at once when the individual test is executed.

Each \emph{subtest} maps to one \emph{two-level test}. The first-level test statistics of subtests are usually related to each other by using the same operation on the tested sequence. For example, the Diehard Craps Test plays 200~000 games of craps. The two calculated first-level test statistics are based on number of wins and GOF test of distribution of throws needed to end the game. \cite{dieharder_orig}

\emph{Variant of the test} is an individual test that is parametrized to search for modified pattern in the data. Only some individual tests allow such parametrization. Usually, all possible \emph{variants} of given individual test are executed.  \cite[p. 2]{vavercak}

The following settings are available in \emph{abstract battery}. They can be set either \emph{globally} with same values for all \emph{individual tests}, or \emph{individually}:
\begin{markdown*}{%
  hybrid,
  definitionLists,
  footnotes,
  inlineFootnotes,
  hashEnumerators,
  fencedCode,
  citations,
  citationNbsps,
  pipeTables,
  tableCaptions,
}

* \emph{number of first-level tests} - Sets how many times the first-level test is repeated (i.e. how many first-level p-values will be produced).
* \emph{size of first-level subsequence} - Sets how long are the subsequences used for first-level test.
* \emph{choose variant} (if applicable for given test).


\end{markdown*}



%(Obratil 3), cite rewind problem (maybe rtt git?)
Originally, the testing batteries were designed to test the random number generators by taking data directly from them as needed. However, common way to test RNG is to take a sample of output, store it into a file and then test contents of the file. The tested file is rewound to the beginning before each individual test (all tests are executed over the same sequence). When the generator is tested directly, every test is executed on 'fresh' sequence. 

Testing files leads to need of \emph{file rewind} detection, which is important part of each battery. File rewinds occurs when the tested file is not large enough for given test configuration. In this case, some parts of the file are tested twice during one test and the results may be biased. The required data size is calculated as \emph{number of first-level tests} $\cdot$ \emph{size of first-level sequence} and it is up to the user to prevent \emph{file rewinds} by configuring the batteries.

%Because unlike random number generators files have limited data size, it is up to user to set the tests to not need more data than are available in the file. Otherwise, when all data from the file have been read but the test needs more, the file is rewound back to the beginning and read again. In such case, the test results might be biased and misleading. The needed data size is calculated as \emph{number of first-level tests} $\cdot$ \emph{size of first-level sequence}.

\subsection{Dieharder} \label{chap:sols-dieharder}
%Explain p-samples, name tests with irregular read bytes, tsample
The \emph{Dieharder} battery was developed by Robert G. Brown at Duke University\cite{dieharder_orig} as an extension to an older \emph{Diehard} battery (created by George Marsaglia). The \emph{Dieharder} is available from \cite{dieharder-git} maintained by Dirk Eddelbuettel or as package in some Unix distributions.

The Dieharder contains 31 individual tests. However, four of them are marked as 'Suspect' or 'Do Not Use' and should not be used. Test variants are possible in four tests.

The \emph{Dieharder} allows all settings as described in the \emph{abstract battery}. They are:
\begin{markdown*}{%
  hybrid,
  definitionLists,
  footnotes,
  inlineFootnotes,
  hashEnumerators,
  fencedCode,
  citations,
  citationNbsps,
  pipeTables,
  tableCaptions,
}
* \emph{psamples} argument sets the number of first-level tests. Default value is 100.
* \emph{tsamples} arguments sets the length of first-level subsequences. Units are \emph{random entities}, which are different size for each test. The tests have various default values, some tests ignore this argument.
* \emph{ntup} argument chooses \emph{test variant} for relevant individual tests.

\end{markdown*}
% add KS test computation
%Second-level test employed in Dieharder is the Kolmogorov-Smirnov test. Assessment of the result is done by the battery resulting is PASSED, WEAK or FAILED. The default value of \emph{significance level} is $\alpha=0.000001$.

% result table description
Results of the \emph{Dieharder} are printed to standard output in a table of results. Each row of the table contains results of one individual test or subtest. Columns contain \emph{test name}, value of \emph{ntup} argument (if applicable, usually 0 otherwise), \emph{tsample} and \emph{psamples} values. Last two columns are the \emph{second-level p-value} and \emph{assessment}. Dieharder output can be modified using \emph{output flags}, including the possibility to print all first-level p-values. Example of Dieharder output can be found in Appendix \ref{append:dieharder-output}.

The \emph{file rewinds} are detected by Dieharder automatically. In such case message '\texttt{\# The file file\textunderscore input\textunderscore raw was rewound <n> times}' is printed to error output. Alternatively, by using dedicated output flag, the amount of data used and this message are printed to standard output after each individual test.

\subsection{NIST STS} \label{chap:sols-nist}
% Second-level p-value x^2, 10 categories (nist_special 4-2)

% NIST overview
The NIST\footnote{National Institute of Standards and Technology} STS\footnote{Statistical Test Suite} was implemented by NIST \cite{nist_special} and is available from \cite{nist_site}. Due to the original implementation being slow, optimized version was developed by CRoCS\footnote{Center for Research on Cryptography and Security} FI MU \cite{nist_faster} available from \cite{nist-opt}. \emph{NIST STS} contains 15 individual tests with no variants. Allowed settings are:
\begin{markdown*}{%
  hybrid,
  definitionLists,
  footnotes,
  inlineFootnotes,
  hashEnumerators,
  fencedCode,
  citations,
  citationNbsps,
  pipeTables,
  tableCaptions,
}
* \emph{Stream count} argument denotes the number of first-level tests and must be set by the user. For a statistically meaningful result of second-level test should be at least 55. 
* \emph{Stream size} argument sets the length of first-level subsequences in \emph{bits} and must be set by the user. The tests have various recommendations for minimal size.
\end{markdown*}

The second-level p-value is computed using the $\chi^2$ test after dividing the first-level p-values into $k=10$ categories. The NIST STS also calculates the proportion of subsequences passing the first-level test. \cite[p. 4-1]{nist_special}.

Tests results are stored in files inside \emph{experiments/AlgorithmTesting} folder. Table with overview of results is in file \emph{finalAnalysisReport.txt}. Each row contains one individual test or subtest. First 10 columns are observed frequencies of first-level p-values in given category. The \emph{second-level p-value, proportion of subsequences passing the first-level test} and test name follow. 

More result information for each test is stored in corresponding folders. In file \emph{stats.txt} the first-level p-values, test statistics and other computational information are stored. In file \emph{results.txt}, only the first level p-values are stored. Example of output is available in Appendix \ref{append:nist-output}.

The file rewinds are detected automatically by the battery. In such case, message '\texttt{READ ERROR:  Insufficient data in file.}' is printed to standard output.


\subsection{Test U01} \label{chap:sols-testu01}
%TODO: no second level assessment
%TODO: output format

TestU01 was developed by Pierre L'Ecuyer and his team at Université de Montrél to be a state-of-the-art software library oriented on testing of random number generators \cite{tu01_paper} and is available from \cite{tu01_site}. It contains several batteries, most important are the \emph{SmallCrush, Crush, BigCrush, Rabbit, Alphabit} and \emph{BlockAlphabit}. Because TestU01 is a software library only, custom command-line interface was created by Ľubomír Obrátil available from \cite{rtt-batteries}, which is described in this subsection.

The TestU01 does not apply a two-level test, but only allows to repeat the single-level test. In TestU01, the \emph{individual test} maps to the repeated \emph{single-level test}. One run of the signle-level test is called \emph{repetition}. If the user wishes to apply the second-level test, they have to examine the distribution of p-values on their own.

Each battery in TestU01 allows for a different set of user settings. All possible arguments in TestU01 are:
\begin{markdown*}{%
  hybrid,
  definitionLists,
  footnotes,
  inlineFootnotes,
  hashEnumerators,
  fencedCode,
  citations,
  citationNbsps,
  pipeTables,
  tableCaptions,
}

* \emph{repetitions} argument sets how many times the single-level test is executed. This argument is used in all batteries.
* \emph{bit\textunderscore nb} argument sets the length of first-level subsequences in \emph{bits}. Applicable (and mandatory) only for Rabbit, Alphabit and BlockAlphabit.
* \emph{bit\textunderscore w} argument is used to choose test variant in \emph{BlockAlphabit} battery.
\end{markdown*}

% output format
The output format is same of for all of TestU01 batteries and is printed to standard output. Only one individual test is executed during one battery run, for which the following is printed. For each repetition of single-level test the test name and all test parameters are printed. Then the test static value and its corresponding p-value are printed (or more values and p-values, if the individual test consists of more subtests). After each repetition, a \emph{generator state} is printed, containing information about how many data were used in all single-level tests so far. And the end of the individual test report, list of all p-values is printed. Example output is in Appendix \ref{append:tu01-output}.

% overflow detection - reading 10MB blocks
File rewind detection is done partially by the batteries using the \emph{generator state} information, however it is up to the user to interpret it. The \emph{generator state} contains three fiels - \emph{bytes need for testing} (number of bytes that were indeed used for testing), \emph{bytes read from file} (number of bytes that were read from tested file) and \emph{total number of file rewinds}. 

Because the data are read from file in 10MB long blocks, the number of file rewinds may be positive, but the number of \emph{bytes needed for testing} will be lower than the actual file size, causing a false alarm. It is up to the user to manually check this situation. % TODO check crush family error detection


%crush family
\subsubsection{SmallCrush, Crush, BigCrush}
Batteries from the \emph{Crush} family were created to test general use random number generators. The batteries contain 10, 96 and 106 tests with increasing demand for data size and runtime. The intended use is to apply SmallCrush for a quick assessment. If the the sequence is accepted, more stringent Crush and BigCrush batteries are applied. The size of first-level sequence cannot be changed. \cite[p. 242]{tu01_guide}

%rabbit
\subsubsection{Rabbit}
The Rabbit battery contains 26 individual tests. The \emph{bit\textunderscore nb} argument must be set by the user to a value of at least 500. \emph{At most} \emph{bit\textunderscore nb} will be used for first-level subsequence size. \cite[p. 152]{tu01_guide} However, several tests require significantly longer subseqeunce than 500 bits. Some tests use significantly shorter subsequence than specified by \emph{bit\textunderscore nb}. Problems with the \emph{bit\textunderscore nb} argument are deeper described in Subsection \ref{chap:analysis-data-rabbit}.

\subsubsection{Alphabit and BlockAlphabit}
Both Alphabit and BlockAlphabit batteries contain the same nine individual test. In the BlockAlphabit battery, the tested data are transformed to deploy \emph{test variants}. The test variant is chosen by the \emph{bit\textunderscore w} argument parametrizing the transformation, which takes values from set \{1, 2, 4, 8, 16, 32\}. \cite[p. 155]{tu01_guide} Size of the first-level sequences will be \emph{at most} the size set by \emph{bit\textunderscore nb} argument.


% FIPS
\subsection{FIPS Battery} \label{chap:sols-fips}
The FIPS\footnote{Federal Information Processing Standards} battery contains five tests and is based on FIPS 140-2 standard. \cite{fips_stand} Custom command-line interface of the battery was created by Patrik Vaverčák available from \cite{rtt-py-batteries}. The interface is based on implementation taken from \cite{fips-site}. No test variants are available and the length of first-level sequence is set to 2500 bytes and cannot be changed \cite[p. 20]{vavercak}. Only one arguments is available:
\begin{markdown*}{%
  hybrid,
  definitionLists,
  footnotes,
  inlineFootnotes,
  hashEnumerators,
  fencedCode,
  citations,
  citationNbsps,
  pipeTables,
  tableCaptions,
}
* \emph{bytes count} argument sets how many bytes will be used for testing \emph{in total}, determining the \emph{number of first-level tests} %$\lfloor bytes\textunderscore~count~\div~2500\rfloor$ .
\end{markdown*}

Output of FIPS battery is printed to standard output and in user-specified file in JSON\footnote{JavaScript Object Notation} format. First, information about accepting or rejecting the null-hypothesis is printed. Then a list of individual tests results is printed. For each individual test, the test name, number of failures and number of runs is printed. Example output is in Appendix \ref{append:fips-output}

File rewinds are detected automatically by the battery. In such case, the battery will not run and will print message '\texttt{Error (<filename>) ! File is not big enough}' to error output.

% BSI
\subsection{BSI battery} \label{chap:sols-bsi}
The BSI\footnote{Bundesamt für Sicherheit in der Informationstechnik} battery contains nine test and is based on series of standards released by BSI. \cite{bsi_stand} Custom command-line interface was created by Patrik Vaverčák, available from \cite{rtt-py-batteries}. The tests implementations were extracted from the ParanoYa application. \cite[p. 16]{vavercak}

No test variants are available in the BSI battery. Each test has its own preset \emph{first-level subsequence size}, which cannot be changed. One argument is available for the battery:
\begin{markdown*}{%
  hybrid,
  definitionLists,
  footnotes,
  inlineFootnotes,
  hashEnumerators,
  fencedCode,
  citations,
  citationNbsps,
  pipeTables,
  tableCaptions,
}
* \emph{bytes count} argument sets how many bytes will be read from the tested file. The number of \emph{first-level tests} is calculated based on this value.
\end{markdown*}

Output of BSI battery is printed to standard output and in user-specified file in JSON format. It contains list of individual tests results. For each individual test, a name and information whether \emph{total error} occurred is printed. If no \emph{total error} occurred, number of failures and number of runs is printed as well. Example output is available in Appendix \ref{append:bsi-output}.

File rewinds are detected automatically by the battery. In such case, the battery will not run and will print message 
'\texttt{File is not big enough}' to error output.



% testing toolkit
\section{Testing toolkits}\label{chap:sols-toolkits}
In the previous section different randomness testing batteries were described. The typical user, however, uses more than one battery, which means installing and running each testing battery individually. Also it is strongly recommended (sometimes even needed) to set up parameters for each test from the battery individually based on size of the tested file and to run this test manually.

Since this approach is not convenient,  CRoCS FI MU created the Randomness Testing Toolkit (\emph{RTT}).\cite{rtt-obratil} This toolkit allows users to run and configure eight test batteries using the same command.

This work was followed by Patrik Vaverčák from Faculty of Electrical Engineering and Information Technology at Slovak University of Technology. He created newer variant of \emph{RTT} called Randomness Testing Toolkit in Python (\emph{rtt-py}). \cite{vavercak}

% RTT OLD
\subsection{Randomness Testing Toolkit} \label{chap:sols-rtt}

\emph{RTT} was created in 2017 and its main idea was to combine \emph{Dieharder}, \emph{NIST STS} and all batteries from \emph{TestU01} mentioned in Subection \ref{chap:sols-testu01} into one program. It was written in C++ and the concept is that \emph{RTT} acts only as a unified interface of the batteries. Each test battery is executed by \emph{RTT} as a separate program. The \emph{RTT} then collects the output and processes it into a unified format.~\cite[p.~8]{rtt-obratil}

RTT is available from CRoCS GitHub repository \cite{rtt-site}. All of the batteries used in RTT are available from a single GitHub repository \cite{rtt-batteries}. Before running, user has to install both the \emph{RTT} and used batteries as described GitHub project wiki. If the user intends to run NIST STS, the \emph{experiments} folder has to be moved (or linked) to \emph{working directory} of RTT. This is not noted anywhere.

\subsubsection{RTT settings}\label{rtt-settings} 
The \emph{RTT} needs to be set up by the user before running. The first part of user settings contains \emph{general settings} of the \emph{RTT}, the second part contains individual \emph{batteries configurations}. Each of these parts is stored in its own JSON file. 

The \emph{general settings} are stored in \emph{rtt-settings.json} file, which has to be located in the working directory of the \emph{RTT}~\cite[p.~10]{rtt-obratil}. These settings are not expected to change. The most important setting from the general part are paths to the executable binaries of individual statistical test batteries. This is the only setting that has to be manually filled in by the user.

The storage database can also be filled in by the user, but this functionality is optional. The following general settings have implicit values and do no need to be changed unless the user wishes to. They are paths to storage directories for results and logs of individual runs and execution options (test timeout and maximal number of parallel executions of tests). Example of \emph{rtt-settings.json} file is in Appendix \ref{append:rtt-setting}.

The battery configurations are dependant on the size of the tested file, therefore the file with the battery configuration is specified for each run of the \emph{RTT} as one of its arguments. These configurations are different for each battery (see Section \ref{chap:sols-batteries}), but they all follow the same format and are stored together in a single file.~\cite[p.~11]{rtt-obratil} The \emph{RTT} contains several prepared battery configurations for various sizes of tested file. Example of battery configuration file is in Appendix \ref{append:rtt-config}.

For each battery, the settings are split into two parts - \emph{defaults} and \emph{test-specific-settings}. The \emph{defaults} section contains IDs of individual tests to be run and default values of all battery arguments. The \emph{test-specific-settings} is a list of all tests whose settings are different than those in \emph{defaults} (along with new settings) or tests which employ test variants. In the second case, all variants to run are listed in entry for the given individual test.

\subsubsection{RTT output}
The output of \emph{RTT} is in a plain text format. The most important part of the output is the direct report, which is saved in the \emph{results} directory. At the beginning of the report are general information -- the name of the tested file, the name of the used battery, ratio of passed and failed individual tests and battery errors and warnings in case there were any.

% terminology - single x individual test
After the general information is a list of results of individual tests in a unified format. The fist part of the individual test report contains the name of the test and user settings. The second part of the individual test report is the second-level p-value alongside the name of statistic used (or more, in case the individual test consists of more subtests). At the end of the individual test report is a list of first-level p-values produced by the test. Example of the output can be seen in Figure \ref{fig:rtt_output_example}.

\begin{figure}
  \begin{center}
    %% minimus is about 100 pixels per 1 centimeter or 300 pixels per 1 inch.
    %% The optimum is about 250 pixels per 1 centimeter 
    \includegraphics[width=12cm]{figures/rtt_dieharder_output.png}
  \end{center}
  \caption{The example of individual test report from the \emph{RTT}}
  \label{fig:rtt_output_example}
\end{figure}


\subsection{Randomness Testing Toolking in Python} \label{chap:sols-rtt-py}
The Randomness Testing Toolkit in Python (\emph{rtt-py}) was created by Patrik Vaverčák. It is supposed to be an improved version of \emph{RTT} sharing the same concept \cite[p.~24]{vavercak} and it was written in Python.

The included batteries are Dieharder, NIST STS, FIPS battery and BSI battery. \emph{Rtt-py} also includes Rabbit, Alphabit and BlockAlphabit batteries from TestU01. The Crush family batteries are not run, even though arguments of \emph{rtt-py} suggest that they are included. The \emph{rtt-py} allows for multiple files to be tested at once.


The \emph{rtt-py} is available from \cite{rtt-py-site} and implementations of all used batteries are available from \cite{rtt-py-batteries}. Before running, both the \emph{rtt-py} and the batteries have to be installed as described in the project's README.



\subsubsection{Rtt-py settings}
The settings of \emph{rtt-py} use same format as the original \emph{RTT} (as described in Subsection \ref{chap:sols-rtt}). The \emph{general settings} from the \emph{RTT} should be one-way compatible with \emph{rtt-py} \cite[p. 25]{vavercak}. In reality there is a problem with settings for the NIST STS's experiments directory. Also, no database connection is implemented in \emph{rtt-py}, therefore the \emph{mysql-db} attribute is ignored. \cite{rtt-py-site}

The second part of user settings are the battery configurations. They use the same format as in \emph{RTT} (as mentioned in \ref{rtt-settings}) and are interchangeable.~\cite[p.~25]{vavercak} The user has to keep in mind that the \emph{rtt-py} uses FIPS and BSI batteries, which are not used in \emph{RTT}. 

\subsubsection{Rtt-py output}
The \emph{rtt-py} creates output in two formats -- \emph{CSV}\footnote{Comma-separated values} and \emph{HTML}\footnote{Hypertext Markup Language}. \cite[p. 36]{vavercak} Both of these report formats contain overview table. Each row from the table represents results of one individual test or subtest. The first column contains the name of the test and the name of the battery it belongs to. The second column contains \emph{failure rate} - ratio of sequences not passing the first-level test.

Each of the following columns is named after one tested file. The record contains either second-level p-value reported by the test, or number of failed runs -- this depends on the battery. Example of this table can be seen at figure \ref{fig:rtt_py_table}.

\begin{figure}
  \begin{center}
    %% minimus is about 100 pixels per 1 centimeter or 300 pixels per 1 inch.
    %% The optimum is about 250 pixels per 1 centimeter 
    \frame{\includegraphics[width=14cm]{figures/rtt-py-table2.png}}
  \end{center}
  \caption{The example of the overview table from the \emph{rtt-py}}
  \label{fig:rtt_py_table}
\end{figure}


The output in the HTML format contains than the output in the CSV format. For each battery and for each tested file an HTML file with reports is generated.

In each report file there is a list of reports for each individual test or subtest from the given battery containing the result (either reported p-value, or number of failed runs). It may contain additional information such as settings of the test or other information connected to the result, depending on the battery and on the executed test. Example of the  report can be seen in figure \ref{fig:rtt_py_html}
\begin{figure}
  \begin{center}
    %% minimus is about 100 pixels per 1 centimeter or 300 pixels per 1 inch.
    %% The optimum is about 250 pixels per 1 centimeter 
    \includegraphics[width=6cm]{figures/rtt-py-dieharder-html.png}
  \end{center}
  \caption{The example of HTML Dieharder report from the \emph{rtt-py}}
  \label{fig:rtt_py_html}
\end{figure}




% TEST ANALYSIS

\chapter{Tests Analysis} \label{chap: analysis}
%We can choose from various test statistics. Most of the test statistics in widely used test batteries work with data of fixed length. TODO: REF ANALYSIS CHAPTER However, in some tests data with varying length are tested. These statistics further split into two categories. In the first category, the length of tested data is preset by user. These can be further viewed as fixed-length tests. In the second category, the length of tested data is determined during the testing process.

This chapter aims to provide more information about the tests from the practical point of view. First, I analysed how much data the tests use to help with configurations of the batteries. As next, I measured how much time each test from the batteries takes to run. Data from both parts were used to create a program for automatic creation of test configurations for \emph{RTT} and \emph{rtt-py} - the \emph{Configuration Calculator}. Last section will done? % is aimed at finding tests with problematic (non-uniform) distributions.


%%%%%%%%%%%%%%%%%%%
% DATA CONSUMPTION
%%%%%%%%%%%%%%%%%%%
%Dieharder X
%Nist - Omit
%Rabbit - to finish
%SmallCrush - X
%Crush - X
%Block(Alphabit) - omit


\section{Data Consumption} \label{chap:analysis-data}
%several big tables, mention exact parameters the tests  were run with

% configurable x fixed size
% variable x constant

% TODO: fix size for tests
As mentioned in Subsection \ref{chap:sols-batteries}, import part of preventing \emph{file rewinds} is correct configuration of the tests. This is a complicated task, because the user has to know size of test first-level subsequences. To help with this task, I performed analysis of sizes of first-level subsequences for Dieharder, SmallCrush, Crush and Rabbit batteries.  % TODO why the rest was omitted

The NIST STS, Alphabit and BlockAlphabit batteries are not shown because the size of first-level subsequence is set by the user. Unlike in Rabbit battery, the tests from mentioned batteries were observed to use the amount of data specified by their arguments. The BigCrush battery was skipped because its first-level subsequence are larger than the currently intended use of RTT.


% INTRODUCTION
\subsection{Introduction} \label{chap:analysis-data-intro}

The idea was to run all tests from the batteries and calculate how many bytes were used for each individual test or test variant based on data provided by the batteries. Based on this information, a table for each battery containing this information was created.

The tests are divided into categories based on two properties. The first property is user's influence on the first-level subseqeunce size. Second property is if \emph{all} runs of the \emph{same} first-level tests use \emph{equal} size of first-level subsequence, or if the first-level subseqeunce size fluctuates between runs. 

In the subsequent text, I use the following terminology. Based on the first property, the tests are called as:
\begin{markdown*}{%
  hybrid,
  definitionLists,
  footnotes,
  inlineFootnotes,
  hashEnumerators,
  fencedCode,
  citations,
  citationNbsps,
  pipeTables,
  tableCaptions,
}
* \emph{Tests with configurable size} are the tests where the size of first-level subsequence can be set by the user.
* \emph{Tests with fixed size} have predefined and unchangable first-level subsequence size.
\end{markdown*}
Based on the second property, the cattegories are called:
\begin{markdown*}{%
  hybrid,
  definitionLists,
  footnotes,
  inlineFootnotes,
  hashEnumerators,
  fencedCode,
  citations,
  citationNbsps,
  pipeTables,
  tableCaptions,
}

* \emph{Tests with constant size} are the tests where the first-level subsequence is equal for all runs.
* \emph{Tests with variable size} are the tests where the first-level subsequence size fluctuates.

\end{markdown*}

The size of the first-level subseqeunce in the tests with variable size is determined by \emph{content} of the sequence. TODO: EXAMPLE FROM DIEHARDER. For an \emph{individual} test from this category and for random content of the sequence, the \emph{real} size of the first-level sequence fluctuates around \emph{some} value. 

To examine how long are the first-level sequences of tests with variable size, I run each test from this category at least 100 times on different \emph{random} data (taken from /dev/random). Tests from this category are presented in their own tables containing mean length of the subsequence and differences between mean and lowest and highest observed length.

To verify that tests with constant size are indeed constant, I run them several times with different number of first-level sequences. The table for them contains only length of the subsequence.



\subsection{Dieharder}

%args
% "../../../rtt-statistical-batteries-master/dieharder", "-f", input_file, "-S 0 -s 1", "-g 201", "-D 131180","-d {}".format(test_id), "-p 25" if test_id in {13, 16} else "-p 5"
In Dieharder both tests with configurable and fixed size are present. All tests with configurable size have a default setting for first-level sequence size, which is usually used. Therefore all tests from this battery are in the analysis viewed as tests with fixed size. The subsequence sizes are presented in three tables.

Table \ref{tab:analysis_dieharder_variable} contains tests with \emph{variable sizes}. The tests with \emph{constant} sizes are split in two tables. In Table \ref{tab:analysis_dieharder}, the tests with \emph{no variants} are shown, the tests \emph{with varints} are shown in Table \ref{tab:analysis_dieharder_variants}.

\begin{table}[H]
  \begin{tabularx}{0.7\textwidth}{c|r|c|c}
    %\toprule
    Test ID & average & $\Delta$ min & $\Delta$ max\\
    \midrule
    13 & 9,225,521 & 0.039\% & 0.038\%\\
    16 & 5,402,335 & 0.126\% & 0.077\%\\
    207 & 452,016,414 & 0.019\% & 0.015\%\\
    208 & 116,881,517 & 0.047\% & 0.014\%\\
 
  \end{tabularx}
  \caption{First-level subseqeunce sizes for Dieharder tests with \emph{variable} sizes.}
  \label{tab:analysis_dieharder_variable}
\end{table}




\begin{table}[H]
  \begin{tabularx}{\textwidth}{lcr}
    {\begin{tabularx}{0.35\textwidth}{lr|r}
        ID & ntup & bytes\\
        \midrule
    200 & 1 & 800,004\\
    200 & 2 & 1,600,004\\
    200 & 3 & 2,400,004\\
    200 & 4 & 3,200,004\\
    200 & 5 & 4,000,004\\
    200 & 6 & 4,800,004\\
    200 & 7 & 5,600,004\\
    200 & 8 & 6,400,004\\
    200 & 9 & 7,200,004\\
    200 & 10 & 8,000,004\\
    200 & 11 & 8,800,004\\
    200 & 12 & 9,600,004\\
    201 & 2 & 80,000\\
    201 & 3 & 120,000\\
    201 & 4 & 160,000\\
    201 & 5 & 200,000\\
    202 & 2 & 800,000\\
    202 & 3 & 1,200,000\\
    202 & 4 & 1,600,000\\
    202 & 5 & 2,000,000 \\ 
    203 & 0 & 4,000,000 \\ 
    203 & 1 & 8,000,000 \\
    203 & 2 & 12,000,000 \\ 
    203 & 3 & 16,000,000 \\
    203 & 4 & 20,000,000 \\
    203 & 5 & 24,000,000 \\
    203 & 6 & 28,000,000 \\
    \end{tabularx}} 
    {\begin{tabularx}{0.1\textwidth}{cc}
      & \\
    \end{tabularx}} 

    {\begin{tabularx}{0.35\textwidth}{lr|r}
        ID & n & bytes\\
        \midrule
        203 & 7 & 32,000,000 \\
        203 & 8 & 36,000,000 \\
        203 & 9 & 40,000,000 \\
        203 & 10 & 44,000,000 \\ 
        203 & 11 & 48,000,000 \\
        203 & 12 & 52,000,000 \\
        203 & 13 & 56,000,000 \\
        203 & 14 & 60,000,000 \\
        203 & 15 & 64,000,000 \\
        203 & 16 & 68,000,000 \\
        203 & 17 & 72,000,000 \\
        203 & 18 & 76,000,000 \\
        203 & 19 & 80,000,000 \\
        203 & 20 & 84,000,000 \\
        203 & 21 & 88,000,000 \\
        203 & 22 & 92,000,000 \\
        203 & 23 & 96,000,000 \\
        203 & 24 & 100,000,000 \\ 
        203 & 25 & 104,000,000 \\
        203 & 26 & 108,000,000 \\
        203 & 27 & 112,000,000 \\
        203 & 28 & 116,000,000 \\
        203 & 29 & 120,000,000 \\
        203 & 30 & 124,000,000 \\
        203 & 31 & 128,000,000 \\
        203 & 32 & 132,000,000 \\
            &    &
    \end{tabularx}} 
  \end{tabularx}
  \caption{First-level subseqeunce sizes for Dieharder tests with \emph{constant} sizes and test variants.}
  \label{tab:analysis_dieharder_variants}
\end{table}

\begin{table}[H]
  \begin{tabularx}{0.65\textwidth}{lcr}
    {\begin{tabularx}{0.25\textwidth}{l|r}
        ID &  bytes\\
        \midrule
        0 & 153,600\\
        1 & 4,000,020\\
        2 & 5,120,000\\
        3 & 2,400,000\\
        4 & 1,048,584\\
        5 & 8,388,608\\
        6 & 5,592,416\\
        7 & 2,621,484\\
        8 & 256,004\\
        9 & 5,120,000\\
        10 & 96,000\\
        11 & 64,000\\
    \end{tabularx}} 
    
    {\begin{tabularx}{0.1\textwidth}{cc}
      & \\
    \end{tabularx}} 

    {\begin{tabularx}{0.3\textwidth}{l|r}
        ID & bytes\\
        \midrule
        12 & 48,000\\
        14 & 796\\
        15 & 400,000\\
        17 & 80,000,000\\
        100 & 400,000\\
        101 & 400,000\\
        102 & 400,000\\
        204 & 40,000 \\
        205 & 614,400,000 \\ 
        206 & 51,200,000 \\
        209 & 260,000,000 \\ 
        &
        
    \end{tabularx}} 
  \end{tabularx}
  \caption{First-level subseqeunces sizes for Dieharder tests with \emph{constant} sizes and no variants.}
  \label{tab:analysis_dieharder}
\end{table}


\subsection{TestU01 SmallCrush and Crush}
In the SmallCrush and Crush batteries, only tests with \emph{fixed} size are present. Both batteries contain tests with \emph{variable} size, which are shown in Table \ref{tab:analysis_smallcrush_variable} for SmallCrush and in Table \ref{tab:analysis_crush_variable} for Crush. The tests with \emph{constant} sizes from SmallCrush are in Table \ref{tab:analysis_smallcrush}, from Crush in  Table \ref{tab:analysis_crush}.


\begin{table}[H]
  \begin{tabularx}{0.75\textwidth}{c|r|r|r}
    %\toprule
    Test ID & average & $\Delta$ min & $\Delta$ max\\
    \midrule
    3 & 204,733,510 & 0.563\% & 0.725\% \\
    5 & 98,731,035 & 0.095\% & 0.087\% \\
  \end{tabularx}
  \caption{First-level subseqeunce sizes for \emph{SmallCrush} tests with \emph{variable} sizes.}
  \label{tab:analysis_smallcrush_variable}
\end{table}

\begin{table}[H]
  \begin{tabularx}{0.4\textwidth}{c|r}
  Test ID & bytes \\
  \midrule
    1 & 40,000,000 \\
    2 & 40,000,000 \\
    4 & 102,400,000 \\
    6 & 48,000,000 \\
    7 & 204,800,000 \\
    8 & 28,800,000 \\
    9 & 120,000,000 \\
    10 & 20,000,000 \\

  \end{tabularx}
  \caption{First-level subseqeunce sizes for \emph{SmallCrush} tests with \emph{constant} sizes.}
  \label{tab:analysis_smallcrush}
\end{table}

\begin{table}[H]
  \begin{tabularx}{0.75\textwidth}{c|r|r|r}
    %\toprule
    Test ID & average & $\Delta$ min & $\Delta$ max\\
    \midrule
    27&1,333,326,306&0.0163\%&0.0166\%\\
    28&1,333,331,101&0.0188\%&0.0170\%\\	
    29&1,974,653,548&0.0189\%&0.0196\%	\\
    30&1,974,640,110&0.0164\%&0.0146\%	\\
    31&3,200,051,704&0.0204\%&0.0306\%	\\
    32&3,199,995,653&0.0380\%&0.0244\%	\\
    33&5,120,635,483&0.1408\%&0.1618\%	\\
    34&5,119,635,549&0.1399\%&0.2516\%	\\
    55&1,653,334,290&0.0065\%&0.0060\%	\\
    64&320,000,610&5.31$\cdot10^{-5}$\% &4.43$\cdot10^{-5}$\%\\
    91&533,332,642&0.0039\%&0.0037\%	\\
    92&1,599,996,811&0.0049\%&0.0043\%\\

  \end{tabularx}
  \caption{First-level subseqeunce sizes for \emph{Crush} tests with \emph{variable} sizes.}
  \label{tab:analysis_crush_variable}
\end{table}


\begin{table}[H]
  \begin{tabularx}{\textwidth}{lcr}
    {\begin{tabularx}{0.30\textwidth}{l|r}
        ID & bytes\\
        \midrule
        1& 2,000,000,000\\
        2& 1,200,000,000\\
        3& 400,000,000\\
        4& 400,000,000\\
        5& 400,000,000\\
        6& 400,000,000\\
        7& 400,000,000\\
        8& 400,000,000\\
        9& 400,000,000\\
        10& 400,000,000\\
        11& 800,000,000\\
        12& 1,200,000,000\\
        13& 1,600,000,000\\
        14& 1,680,000,000\\
        15& 1,680,000,000\\
        16& 1,920,000,000\\
        17& 1,920,000,000\\
        18& 160,000,000\\
        19& 240,000,000\\
        20& 280,000,000\\
        21& 128,000,000\\
        22& 128,000,000\\
        23& 2,560,000,000\\
        24& 2,560,000,000\\
        25& 2,560,000,000\\
        26& 2,560,000,000\\
        35& 2,000,000,000\\
        36& 2,000,000,000\\
    \end{tabularx}} 
    
    {\begin{tabularx}{0.05\textwidth}{cc}
      & \\
    \end{tabularx}} 
    
    {\begin{tabularx}{0.30\textwidth}{l|r}
        ID & bytes\\
        \midrule
        37& 2,000,000,000\\
        38& 2,000,000,000\\
        39& 2,600,000,000\\
        40& 2,600,000,000\\
        41& 2,000,000,000\\
        42& 2,000,000,000\\
        43& 800,000,000\\
        44& 1,200,000,000\\
        45& 400,000,000\\
        46& 1,200,000,000\\
        47& 800,000,000\\
        48& 2,000,000,000\\
        49& 820,000,000\\
        50& 880,000,000\\
        51& 2,048,000,000\\
        52& 2,048,000,000\\
        53& 2,048,000,000\\
        54& 2,048,000,000\\
        56& 480,000,000\\
        57& 1,440,000,000\\
        58& 600,000,000\\
        59& 1,800,000,000\\
        60& 384,000,000\\
        61& 1,152,000,000\\
        62& 2,400,000,000\\
        63& 800,000,000\\
        65& 600,000,000\\
        66& 360,000,000\\
    \end{tabularx}} 
    
    {\begin{tabularx}{0.05\textwidth}{cc}
      & \\
    \end{tabularx}} 
    
    {\begin{tabularx}{0.30\textwidth}{l|r}
        ID & bytes\\
        \midrule
        67& 680,000,000\\
        68& 400,000,000\\
        69& 668,000,000\\
        70& 400,000,000\\
        71& 480,000\\
        72& 480,000\\
        73& 44,739,280\\
        74& 109,400,000\\
        75& 327,800,000\\
        76& 1,333,336,000\\
        77& 1,200,002,400\\
        78& 1,200,000,000\\
        79& 1,200,000,000\\
        80& 1,333,360,000\\
        81& 1,200,000,000\\
        82& 2,000,000,000\\
        83& 2,000,000,000\\
        84& 1,600,000,000\\
        85& 2,400,000,000\\
        86& 2,400,000,000\\
        87& 2,400,000,000\\
        88& 2,400,000,000\\
        89& 3,200,000,000\\
        90& 960,000,000\\
        93& 1,333,333,400\\
        94& 2,000,000,020\\
        95& 1,333,333,400\\
        96& 2,000,000,040\\

    \end{tabularx}} 
  \end{tabularx}
  \caption{First-level subseqeunce sizes for \emph{Crush} tests with \emph{constant} sizes.}
  \label{tab:analysis_crush}
\end{table}






% several tables, at least table for minims
\subsection{TestU01 Rabbit} \label{chap:analysis-data-rabbit}
All tests in the Rabbit battery are with \emph{configurable} size. The size is configured using the \emph{bit\textunderscore nb} argument, where the desired size is entered in \emph{bits} and for use is rounded down to closest multiple of 32. The \emph{bit\textunderscore nb} has no default value, must be at least 500 and \emph{at most} \emph{bit\textunderscore nb} bits will be read from the file. \cite[p. 152]{tu01_guide} However, almost half of the tests require bigger \emph{bit\textunderscore nb} and will not run otherwise. These tests and their required sizes are in Table \ref{tab:analysis_rabbit_minims}. The minims were found and verified experimentally.

\begin{table}[H]
  \begin{tabularx}{0.4\textwidth}{c|r}
    %\toprule
    Test ID & minimal \emph{bit\textunderscore nb}\\
    \midrule
    9& 31,200\\
    10& 960\\
    11& 960\\
    15& 960\\
    16& 1,920\\
    17& 3,840\\
    21& 51,200\\
    22& 5,120,000\\
    23& 52,428,800\\
    24& 960\\
    25& 30,720\\
    26& 300,480\\
  \end{tabularx}
  \caption{Minimal values of \emph{bit\textunderscore nb} argument other than default needed to run tests from \emph{Rabbit} battery.}
  \label{tab:analysis_rabbit_minims}
\end{table}

Tests 6, 7 and 8 read only data with size $2^k$($k \in \mathbb{N}$) \emph{bits}. The possible values of $k$ are different for each test and shown in Table \ref{tab:analysis_rabbit_two_powers}. \cite[p.~124-126]{tu01_guide} If the \emph{bit\textunderscore nb} is not power of two, closest lower applicable power of 2 is used. The \emph{bit\textunderscore nb} still has to be at least 500, even though smaller amount of bits may be used.

\begin{table}[H]
  \begin{tabularx}{0.33\textwidth}{c|c}
    %\toprule
    Test ID & maximal $k$\\
    \midrule
    6& 28\\
    7& 20\\
    8& 26\\
 
  \end{tabularx}
  \caption{Maximal values of $k$ for Rabbit tests which take data of size $2^k$ \emph{bits}.}
  \label{tab:analysis_rabbit_two_powers}
\end{table}

The only test with \emph{variable} size from Rabbit battery is 20. It uses around 80 \% of data size specified by \emph{bit\textunderscore nb} argument. Test 5 reads significantly less data than specified. When the \emph{bit\textunderscore nb} argument specifies that the test should use 10MB of data, the test 5 uses only  3,536 \emph{bytes}. When the test should use 100MB of data, it uses only 8,488 \emph{bytes}.

For some tests there is an \emph{upper bound} of data used for testing. The test will not read more data, even with growing \emph{bit\textunderscore nb}. Size of the data that are actually read from the file is not constant in such case and fluctuates around \emph{some} values, even when the test should read more data. Examples of real data size fluctuation is at Figure \ref{fig:analysis-rabbit-max}.

\begin{figure}
  \begin{center}
    \includegraphics[width=12.5cm]{figures/rabbit_3_maxims.png}
  \end{center}
  \caption{Number of bytes actually read from tested file by Rabbit test 3 for increasing \emph{bit\textunderscore nb} > 3.3$\cdot10^{9}$.}
  \label{fig:analysis-rabbit-max}
\end{figure}
%\todo{moving upper bound}
%For the following analysis of first-level subseqeunce sizes the \emph{bit\textunderscore nb} argument was fixed to value 52,428,800. This is the lowest value for which all tests from Rabbit, Alphabit and BlockAlphabit will run (all batteries from TestU01 using \emph{bit\textunderscore nb} argument).

%TODO: maximal sizes

%%%%%%%%%%%%%%%%%%%
% Time consumption
%%%%%%%%%%%%%%%%%%%

% Dieharder X 
% Nist X
% SmallCrush X
% Crush X
% Rabbit X
% Alphabit X

\section{Time consumption and performance} \label{chap:analysis-times}
%again some big tables, choose one test as a reference and the rest will be relative. mention exact parameters, maybe add throughput?


Another analysis I performed is examination of the tests' runtimes and performance. This may be used to \emph{exempt} tests that would take \emph{unreasonably} long to execute or to detect problems while running the tests (for example when the test execution gets stuck on non-random data).

Because the runtimes highly depend on used machine and the idea is to make relative comparison between the tests only, they are presented in \emph{relative} form compared to the runtime of Diehard 3d Sphere (Minimum Distance) Test from Dieharder battery (later refered to as \emph{time unit} or \emph{TU}).\footnote{Running on Intel Core i7-1065G7 CPU under Ubuntu 22.04.1 WSL on Windows~10 this test took 0.021 seconds.} 

To compare performance of the tests, \emph{throughput} was chosen as a measure. It is presented alongside the runtime. The throughput is calculated as kilobytes\footnote{1024 bytes} of data processed per time unit. 

The used implementations of batteries are taken from RTT (available from \cite{rtt-batteries}). The batteries were run directly (i.e. not using RTT) and each individual test was executed in separate at least one hundred times. Mean runtime over these runs is presented in this Section.

The runtimes and throughputs for Dieharder are in Table \ref{tab:analysis_time_dieharder}. The Dieharder tests were run without the \emph{rate} option and with default values of \emph{tsample} argument. Runtimes and throughputs for TestU01 SmallCrush and Crush batteries are in Table \ref{tab:analysis_smallcrush_time} and Table \ref{tab:analysis_crush_times}.

To measure runtimes of test with \emph{configurable} size, I had to fix the first-level subsequence size for each test. For NIST STS battery, I set \emph{stream size} argument to 1,000,000 (the subsequences were 250,000  bytes long). This is the lowest value which satisfies subsequence size recommendations for all the tests. \cite{nist_special} NIST STS runtimes and throughputs are shown in Table \ref{tab:analysis_nist_time}.

For TestU01 Rabbit, Alphabit and BlockAlphabit batteries, I fixed the \emph{bit\textunderscore nb} argument to value 52,428,800 (the subseqeunces should be 6,553,600 bytes long). This is the lowest value for which all tests from the three batteries are executed (see Subsection \ref{chap:analysis-data-rabbit}). The runtimes and throughputs for Rabbit battery are in Table \ref{tab:analysis_rabbit_time}. Alphabit and BlockAlphabit batteries share Table \ref{tab:analysis_alphabit_time}, because both batteries employ the \emph{same} tests and no difference in runtimes was observed.

\begin{table}[H]
  \begin{tabularx}{1\textwidth}{lcr}
    {\begin{tabularx}{0.43\textwidth}{c|r|r}
        ID & runtime & Throughput\\
         & (TU) & (kB/TU) \\
        \midrule
        0 & 0.43 & 347 \\
        1 & 2.93 & 1332 \\
        2 & 9.28 & 539 \\
        3 & 2.10 & 1116 \\
        4 & 0.91 & 1126 \\
        5 & 4.79 & 1710 \\
        6 & 33.36 & 164 \\
        7 & 10.01 & 256 \\
        8 & 0.21 & 1208 \\
        9 & 2.86 & 1751 \\
        10 & 0.73 & 128 \\
        11 & 0.27 & 236 \\
        12 & 1.00 & 47 \\
        13 & 5.70 & 1581 \\
    \end{tabularx}} 
    {\begin{tabularx}{0.1\textwidth}{cc}
      & \\
    \end{tabularx}} 

    {\begin{tabularx}{0.43\textwidth}{c|r|r}
        ID & runtime & Throughput\\
         & (TU) & (kB/TU) \\
        \midrule 
        14 & 3.03$\cdot10^{-5}$ & 25598 \\
        15 & 0.25 & 1585 \\
        16 & 2.86 & 1846 \\
        17 & 75.79 & 1031 \\
        100 & 0.19 & 2024 \\
        101 & 2.73 & 143 \\
        102 & 4.29 & 91 \\
        204 & 0.06 & 604 \\
        205 & 311.59 & 1926 \\
        206 & 44.78 & 1117 \\
        207 & 272.13 & 1622 \\
        208 & 180.61 & 632 \\
        209 & 266.52 & 953 \\
         & &\\

    \end{tabularx}} 
  \end{tabularx}
  \caption{Runtimes for and throughputs Dieharder battery tests without variants.}
  \label{tab:analysis_time_dieharder}
\end{table}

\begin{table}[H]
  \begin{tabularx}{1\textwidth}{lcr}
    {\begin{tabularx}{0.5\textwidth}{c|c|r|r}
        ID & ntup & runtime & Through\\
         & & & put \\
         & & (TU) & (kB/TU) \\
        \midrule
        200 & 1 & 1.18 & 662 \\
        200 & 2 & 1.59 & 983 \\
        200 & 3 & 1.89 & 1238 \\
        200 & 4 & 2.30 & 1359 \\
        200 & 5 & 3.02 & 1295 \\
        200 & 6 & 4.20 & 1116 \\
        200 & 7 & 5.98 & 915 \\
        200 & 8 & 7.06 & 885 \\
        200 & 9 & 8.90 & 790 \\
        200 & 10 & 11.40 & 685 \\
        200 & 11 & 15.90 & 540 \\
        200 & 12 & 24.84 & 377 \\
        201 & 2 & 0.28 & 279 \\
        201 & 3 & 0.34 & 347 \\
        201 & 4 & 0.50 & 310 \\
        201 & 5 & 0.87 & 225 \\
        202 & 2 & 0.47 & 1666 \\
        202 & 3 & 0.74 & 1590 \\
        202 & 4 & 1.09 & 1436 \\
        202 & 5 & 1.89 & 1033 \\
        203 & 0 & 2.00 & 1956 \\
        203 & 1 & 3.86 & 2025 \\
        203 & 2 & 5.88 & 1994 \\
        203 & 3 & 7.70 & 2030 \\
        203 & 4 & 9.90 & 1973 \\
        203 & 5 & 11.67 & 2009 \\
        203 & 6 & 13.63 & 2006 \\
    \end{tabularx}} 
    %{\begin{tabularx}{0.1\textwidth}{cc}
    %  & \\
    %\end{tabularx}} 

    {\begin{tabularx}{0.5\textwidth}{c|c|r|r}
       ID & ntup & runtime & Through\\
         & & & put \\
         & & (TU) & (kB/TU) \\
        \midrule 
        203 & 7 & 16.04 & 1948 \\
        203 & 8 & 17.64 & 1993 \\
        203 & 9 & 19.59 & 1994 \\
        203 & 10 & 21.24 & 2023 \\
        203 & 11 & 23.44 & 2000 \\
        203 & 12 & 25.24 & 2012 \\
        203 & 13 & 27.15 & 2014 \\
        203 & 14 & 29.19 & 2008 \\
        203 & 15 & 30.76 & 2032 \\
        203 & 16 & 32.89 & 2019 \\
        203 & 17 & 35.10 & 2003 \\
        203 & 18 & 36.79 & 2017 \\
        203 & 19 & 38.98 & 2004 \\
        203 & 20 & 40.36 & 2032 \\
        203 & 21 & 42.82 & 2007 \\
        203 & 22 & 44.86 & 2003 \\
        203 & 23 & 46.18 & 2030 \\
        203 & 24 & 49.11 & 1989 \\
        203 & 25 & 50.01 & 2031 \\
        203 & 26 & 51.24 & 2058 \\
        203 & 27 & 55.30 & 1978 \\
        203 & 28 & 57.85 & 1958 \\
        203 & 29 & 58.84 & 1992 \\
        203 & 30 & 61.32 & 1975 \\
        203 & 31 & 64.50 & 1938 \\
        203 & 32 & 65.41 & 1971 \\
         \\

    \end{tabularx}} 
  \end{tabularx}
  \caption{Runtimes and throughputs for Dieharder battery tests with variants.}
  \label{tab:analysis_time_dieharder_variants}
\end{table}



\begin{table}[H]
  \begin{tabularx}{0.5\textwidth}{c|r|r}
    %\toprule
    Test ID & runtime & throughput\\
     & (TU) & (kB/TU) \\
    \midrule
    1 & 0.16 & 782 \\
    2 & 0.17 & 716 \\
    3 & 0.16 & 765 \\
    4 & 0.19 & 658 \\
    5 & 0.17 & 711 \\
    6 & 0.24 & 500 \\
    7 & 5.79 & 21 \\
    8 & 0.77 & 158 \\
    9 & 0.20 & 597 \\
    10 & 0.22 & 560 \\
    11 & 0.22 & 561 \\
    12 & 0.43 & 283 \\
    13 & 0.39 & 314 \\
    14 & 0.93 & 132 \\
15 & 1.55 & 79 \\
  \end{tabularx}
  \caption{Runtimes and throughputs for NIST STS battery with \emph{stream size} 1,000,000 bits.}
  \label{tab:analysis_nist_time}
\end{table}


\begin{table}[H]
  \begin{tabularx}{0.5\textwidth}{c|r|r}
    Test ID & Runtime & Throughput\\
     & (TU) & (kB/TU) \\
    \midrule
    1 & 49.20 & 794 \\
    2 & 36.48 & 1071 \\
    3 & 16.21 & 12361 \\
    4 & 16.74 & 5973 \\
    5 & 13.03 & 7402 \\
    6 & 17.24 & 2719 \\
    7 & 12.94 & 15451 \\
    8 & 16.07 & 1750 \\
    9 & 22.76 & 5149 \\
    10 & 25.56 & 764 \\
  \end{tabularx}
  \caption{Runtimes and throughputs for TestU01 SmallCrush battery.}
  \label{tab:analysis_smallcrush_time}
\end{table}


\begin{table}[H]
  \begin{tabularx}{\textwidth}{lcr}
    {\begin{tabularx}{0.33\textwidth}{c|r|r}
        ID & time & thr\\
         & (TU) &  kb/\\
         & & TU \\
        \midrule
        1 & 691.72 & 2824 \\
2 & 412.71 & 2839 \\
3 & 706.53 & 553 \\
4 & 744.61 & 525 \\
5 & 1001.45 & 390 \\
6 & 1014.13 & 385 \\
7 & 1046.35 & 373 \\
8 & 1033.21 & 378 \\
9 & 995.59 & 392 \\
10 & 1005.83 & 388 \\
11 & 960.15 & 814 \\
12 & 972.95 & 1204 \\
13 & 1001.15 & 1561 \\
14 & 644.60 & 2545 \\
15 & 675.67 & 2428 \\
16 & 651.24 & 2879 \\
17 & 644.66 & 2908 \\
18 & 296.66 & 527 \\
19 & 408.85 & 573 \\
20 & 763.62 & 358 \\
21 & 290.98 & 430 \\
22 & 249.12 & 502 \\
23 & 356.42 & 7014 \\
24 & 418.57 & 5973 \\
25 & 340.36 & 7345 \\
26 & 414.22 & 6035 \\
27 & 175.32 & 7427 \\
28 & 210.22 & 6194 \\
29 & 217.71 & 8858 \\
30 & 256.83 & 7508 \\
31 & 227.35 & 13745 \\
32 & 288.64 & 10827 \\

    \end{tabularx}} 
    
    %{\begin{tabularx}{0.05\textwidth}{cc}
     % & \\
    %\end{tabularx}} 
    
    {\begin{tabularx}{0.33\textwidth}{c|r|r}
        ID & time & thr\\
         & (TU) &  kb/\\
         & & TU \\
        \midrule
        33 & 249.16 & 20070 \\
34 & 310.39 & 16108 \\
35 & 210.76 & 9267 \\
36 & 277.00 & 7051 \\
37 & 685.43 & 2849 \\
38 & 694.09 & 2814 \\
39 & 1217.74 & 2085 \\
40 & 1261.90 & 2012 \\
41 & 802.82 & 2433 \\
42 & 474.13 & 4119 \\
43 & 115.48 & 6765 \\
44 & 131.44 & 8916 \\
45 & 80.57 & 4848 \\
46 & 128.67 & 9108 \\
47 & 157.27 & 4968 \\
48 & 146.23 & 13356 \\
49 & 239.32 & 3346 \\
50 & 82.72 & 10389 \\
51 & 101.95 & 19618 \\
52 & 131.29 & 15233 \\
53 & 147.27 & 13580 \\
54 & 152.78 & 13090 \\
55 & 109.68 & 14721 \\
56 & 770.92 & 608 \\
57 & 808.59 & 1739 \\
58 & 1164.27 & 503 \\
59 & 1379.70 & 1274 \\
60 & 1567.96 & 239 \\
61 & 2014.98 & 558 \\
62 & 164.67 & 14233 \\
63 & 513.08 & 1523 \\
64 & 148.90 & 2099 \\

    \end{tabularx}} 
    
   % {\begin{tabularx}{0.05\textwidth}{cc}
    %  & \\
    %\end{tabularx}} 
    {\begin{tabularx}{0.33\textwidth}{c|r|r}
        ID & time & thr\\
         & (TU) &  kb/\\
         & & TU \\
        \midrule
        65 & 843.17 & 695 \\
66 & 207.06 & 1698 \\
67 & 682.89 & 972 \\
68 & 177.12 & 2205 \\
69 & 581.06 & 1123 \\
70 & 157.27 & 2484 \\
71 & 522.24 & 1 \\
72 & 518.17 & 1 \\
73 & 632.92 & 69 \\
74 & 561.55 & 190 \\
75 & 599.53 & 534 \\
76 & 2024.52 & 643 \\
77 & 708.19 & 1655 \\
78 & 599.47 & 1955 \\
79 & 371.55 & 3154 \\
80 & 335.88 & 3877 \\
81 & 221.70 & 5286 \\
82 & 544.90 & 3584 \\
83 & 521.43 & 3746 \\
84 & 401.77 & 3889 \\
85 & 648.33 & 3615 \\
86 & 486.71 & 4815 \\
87 & 642.08 & 3650 \\
88 & 478.61 & 4897 \\
89 & 835.60 & 3740 \\
90 & 184.36 & 5085 \\
91 & 796.39 & 654 \\
92 & 952.65 & 1640 \\
93 & 540.12 & 2411 \\
94 & 659.61 & 2961 \\
95 & 447.90 & 2907 \\
96 & 527.98 & 3699 \\

    \end{tabularx}} 
  \end{tabularx}
  \caption{Runtime and throughputs for TestU01 \emph{Crush} battery.}
  \label{tab:analysis_crush_times}
\end{table}


\begin{table}[H]
  \begin{tabularx}{1\textwidth}{lcr}
    {\begin{tabularx}{0.43\textwidth}{c|r|r}
                ID & runtime & throughput\\
         & (TU) &  kb/TU\\
        \midrule
        1 & 448.60 & 14 \\
        2 & 16.52 & 387 \\
        3 & 11.68 & 548 \\
        4 & 1.59 & 4019 \\
        5 & 20.32 & 0 \\
        6 & 70.27 & 58 \\
        7 & 2.57 & 50 \\
        8 & 20.29 & 315 \\
        9 & 10.62 & 603 \\
        10 & 3.62 & 1769 \\
        11 & 2.14 & 2988 \\
        12 & 2.07 & 3091 \\
        13 & 2.04 & 3143 \\
    \end{tabularx}} 
    {\begin{tabularx}{0.1\textwidth}{cc}
      & \\
    \end{tabularx}} 

    {\begin{tabularx}{0.43\textwidth}{c|r|r}
       ID & runtime & throughput\\
         & (TU) &  kb/TU\\
        \midrule 
        14 & 2.16 & 2964 \\
        15 & 2.60 & 2458 \\
        16 & 2.10 & 3053 \\
        17 & 2.17 & 2953 \\
        18 & 3.01 & 2129 \\
        19 & 3.00 & 2136 \\
        20 & 8.55 & 599 \\
        21 & 10.62 & 603 \\
        22 & 13.26 & 483 \\
        23 & 22.71 & 282 \\
        24 & 9.26 & 691 \\
        25 & 7.02 & 912 \\
        26 & 6.08 & 1052 \\
    \end{tabularx}} 
  \end{tabularx}
  \caption{Runtimes and throughputs for TestU01 Rabbit battery with \emph{bit\textunderscore nb} 52,428,800}
  \label{tab:analysis_rabbit_time}
\end{table}


\begin{table}[H]
  \begin{tabularx}{0.5\textwidth}{c|r|r}
  Test ID & Runtime & Throughput \\
         & (TU) &  kb/TU\\
  \midrule
        1 & 3.49 & 1835 \\
        2 & 3.51 & 1825 \\
        3 & 3.36 & 1902 \\
        4 & 5.72 & 1119 \\
        5 & 2.60 & 2459 \\
        6 & 2.11 & 3034 \\
        7 & 2.06 & 3109 \\
        8 & 10.52 & 608 \\
        9 & 8.07 & 793 \\
  \end{tabularx}
  \caption{Runtimes and throughputs for TestU01 Alphabit and BlockAlphabit batterires with \emph{bit\textunderscore nb} 52,428,800.}
  \label{tab:analysis_alphabit_time}
\end{table}

%%%%%%%%%%%%%%
% CONFIG CALC
%%%%%%%%%%%%%%

\section{Configuration Calculator} \label{chap:analysis-config-calc}
\todo{appendix examples, git link (when ready)}

The information collected in Sections \ref{chap:analysis-data} and \ref{chap:analysis-times} were used in the \emph{Configuration Calculator}. I created this tool to automate creation of battery configuration files for \emph{RTT}. Configuration Calculator supports all batteries that are present in \emph{RTT} except the TestU01 BigCrush battery.

\subsection{Batteries configurations}

The configurations are created based on the length of the tested data. Number of first-level subsequences for each individual test is set so that the test will use as much data as possible without \emph{file rewind}.

For tests with \emph{configurable} size, the default values were chosen the same as in Section \ref{chap:analysis-times}. For NIST STS the \emph{stream size} is set to 1,000,000 \emph{bits} and for TestU01 Rabbit, Alphabit and BlockAlphabit, the \emph{bit\textunderscore nb} is set to  52,428,800 \emph{bits}. The user may choose their own value for these arguments.

For all individual test the number of first-level tests is calculated as $\lfloor tested\:file\:size \div first$-$level\:subsequence\:size\rfloor$. For tests with \emph{constant} size, the direct subsequence size is used. For tests with \emph{variable} size the fluctuation of first-level sequence sizes has to be taken into account to prevent \emph{file rewinds}. To achieve this, mean first-level subseqeunce size increased by a buffer is used as the subsequence size. The buffer size was chosen to be 1\% of the subseqeunce size for tests from TestU01 batteries and 0.1\% for tests from Dieharder. Based on analysis from Section \ref{chap:analysis-data}, this should be enough to prevent file rewinds caused by the size fluctuation.

In total 7 tests are always omitted by the Configuration Calculator. Tests 5, 6, 7 and 14 from Dieharder battery are skipped because they are marked as 'Do Not Use' or 'Suspect' by Dieharder. From Crush battery tests 71 and 72 were removed due to their low performance (see Table \ref{tab:analysis_crush_times}). Running each of the two tests would take 12 times longer than running \emph{all} of the remaining tests. The test 5 from Rabbit was also omitted due to low performance (see Table \ref{tab:analysis_rabbit_time}).


\subsection{Output Format}
Format of the configuration files created by the Configuration Calculator is extension of the original format used by \emph{RTT} (described in Subsection \ref{chap:sols-rtt}). It contains no new \emph{functional} fields, only information for the user. First such field is \emph{omitted-tests} inside \emph{battery-settings} -- tests that will not be run. Either because the tested file is to small for them or because they were removed by default.

Second new field is \emph{battery-defaults}. It contains default argument settings for a given battery and default settings for each individual test, along with the test name and used first-level subsequence sizes. Both \emph{battery-settings} and \emph{battery-defaults} contain also comments for some individual tests with information about why the test was omitted or warning that a given test is with \emph{variable} size.



\section{P-values uniformity} \label{chap:analysis-uniform}
% intro (correcting dieharder - 2, 7)
% intro - not uniform in reality,  motivation, mention each battery
% show some really bad examples
As was mentioned in Section \ref{chap:rand-two_level}, crucial part of two-level testing is examination of observed first-level p-values distribution. The expected theoretical distribution is uniform on interval (0,1]. \cite[p.~14]{bad_day} Due to various reaons, the real distribution (under the null-hypothesis) may differ from the uniform distribution. This may lead to flawed results of second-level tests. In this section, reasons why this happens are presented along examples of real observed distributions of first-level p-values. It is not goal of this thesis to fix the problem, only to note it.

In the following text, some examples of tests with non-uniform distributions are presented. The data for real distributions were acquired by repeatedly generating files with 5GB of random data using the AES\footnote{Advanced Encryption Standard} with known key as random number generator. Each file was tested using the \emph{RTT} with battery configuration generated by the Configuration Calculator. 
TODO: CITE UNRELEASED PAPER

The reason why non-uniform distributions are observed is that the distributions of test statistic values in first-level tests are usually approximated in the calculation. This is usually done because the real distribution is know only asymptotically or because it is more efficient. Also, the distribution of test statistic values (and therefore p-values), for a fixed sample size, is in fact discrete, but a continuous distribution is often used as approximation to calculate the p-value. This causes error, which accumulates alongside the error caused by limited-precision calculations. \cite[p. 7]{bad_day}

Possible outcomes of previous situations are non-uniform distributions of the first-level p-values. The first situation are discrete distributions with \emph{low} number of possible p-values. The most extreme are distributions with only \emph{a few} possible p-values, for example the Rabbit 3 test, in which only six different p-values were observed over the course of almost 840,000 runs . The less extreme tests have lower hundreds of possible first-level p-values, for example the Dieharder 10 test, which produced 221 different p-values over 10,000,000 runs.

More common are tests with high number of observed p-values, but non-uniform distribution. The real distributions are usually \emph{close} to the uniform distribution, but differ in tails (values in tail are significantly more or less probable). Examples of all described flawed distributions can be seen in Figure \ref{fig:uniforms}.

\begin{figure}
  \begin{center}
    %% minimus is about 100 pixels per 1 centimeter or 300 pixels per 1 inch.
    %% The optimum is about 250 pixels per 1 centimeter 
    \includegraphics[width=13cm]{figures/uniformity.png}
  \end{center}
  \caption{Histograms for example of first-level p-values distributions.}
  \label{fig:uniforms}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% IMPLEMENTATIONS COMPARISON
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Implementations comparison}

The \emph{rtt-py} is supposed to be a newer version of \emph{RTT} and might replace it in the future. Therefore, in this chapter I focus mainly on finding differences between the two. The first section aims at comparing outputs of both testing toolkits. In the second section I am at finding functional differences between them, especially the features the are present in \emph{RTT} and not in \emph{rtt-py}. In the last section I present general suggestions for further improvement of both \emph{RTT} and \emph{rtt-py}. 

% COMPARE OUTPUT
% X - contents of the output
% parsing
%  - rtt - vše v paměti, out of memory error, dlouhé parsonvání
% X - format
% warningy - RTT parsuje slovo WARN/ERROR
\section{Output}
\todo{? add info about parsing ?}
First difference in output between \emph{RTT} and \emph{rtt-py} is the format of the output. \emph{RTT} offers reports only in plaintext format, which contains all of the reported information (see Subsection \ref{chap:sols-rtt}). The format is human-readable, but hard to navigate. Computer processing requires rather complicated parsing.

The \emph{rtt-py} offers an overview table in HTML and CSV formats, which are both human-readable and usefull for quick assessment of the result of the tests. The CSV format is also easily computer-readable. The full HTML format offers more information, usually regarding the test settings. TODO: New info for result assessment In the NIST STS, the proportion of sequences passing the first-level test is added. In the TestU01 batteries, corresponding test statistics values are part of the HTML report as well.

The main functional difference in output between \emph{RTT} and \emph{rtt-py} are the reported information. For this comparison, the full HTML report from \emph{rtt-py} is taken. Both toolkits report the resulting second-level p-values for Dieharder and both the second-level p-value and proportion of sequences passing the first-level test for NIST STS batteries. However, unlike \emph{RTT}, the \emph{rtt-py} does not report first-level p-values, which could be useful for deeper assessment of the results. The \emph{RTT} also reports more information regarding the details about individual tests from NIST STS battery.


For the TestU01 batteries, which employ only repeated single-level tests, the reported information are the same for both toolkits. However, in \emph{RTT} report, repetitions of the same individual test are grouped together and their respective p-values are printed together. In \emph{rtt-py}, each repetition is treated as a separate individual test. The p-values are printed, but the user has to manually group the tests by their names. This is important, because the TestU01 does not perform the two-level test and if the user wishes to apply it, they have to do so on their own. Both toolkits also report additional details regarding the individual test.



% MISSING FEATURES
% X - first-level p-values  
% X - running Crush family
% check - alphabit and rabbit
% X - detekce errors / warnings
\section{Missing Features of \emph{rtt-py}}
One of the problems that need to be addressed is that the \emph{rtt-py } ignores errors and warnings from tests. The most notable example why this is a problem are the \emph{file rewinds}.

In this case, the test will read some parts of the data more than once and inform the user about this situation on the error output. The test will still produce result, which will, however, be biased by repeated parts of the tested file.

This may lead to incorrect interpretation of the results and to Type I or II error. Since the \emph{rtt-py} ignores this, there is no way for the user to be informed about this situation.

% first-level pvals
As was mentioned in previous section, unlike \emph{RTT}, the \emph{rtt-py} does not report first-level p-values from Dieharder and NIST STS. The first-level p-values can be usefull for deeper examination of the tests results.

%TODO: testu01 batteries - no test specific settings
Batteries from the \emph{TestU01 Crush} family are not run by the \emph{rtt-py}. However, the program options suggest that the batteries are contained. Also, the \emph{rtt-py} ignores the \emph{test-specific-settings} field from the battery configuration files for TestU01 Rabbit, Alphabit and BlockAlphabit batteries.


%There are two most notable disadvantages of the \emph{RTT}. The first one is that each battery has to be run individually by the user. This lowers the convenience of usage for the user. The second one is the output format. While it is easy to read for human users, machine reading requires complicated parsing. 


% rtt-py adding first-level p-values
% rtt-py adding errors
% X - tests setup - config calc
% X - our own second-level assessment
% X - computer - readable format
\section{Proposed improvements}
First proposed improvement for both \emph{RTT} and \emph{rtt-py} is better way to configure the batteries. While \emph{RTT} offers some prepared configuration files, they are not available for all file sizes. Also, some of the configuration files contained configurations that resulted in \emph{file rewinds} or the tests read less data than was possible, resulting in testing only a part of the file. I implemented this improvement in the form of Configuration Calculator (see Subsection \ref{chap:analysis-config-calc}).

Second proposed improvement are better second level-tests. As is shown in Subsection \ref{chap:analysis-uniform}, p-values of many first-level tests do not follow the uniform distribution. The improved second-level tests should take these non-uniform distributions into account and compare the observed distributions to the real distributions of the tests. The improved second-level tests also should provide second-level assessment of the TestU01 batteries.

Third proposed improvement is to extend the output format of \emph{RTT} to computer-readable format, possibly using JSON format as in configurations. This could be used not only for quick computer-made results assessments, but also for the custom second-level tests.


%%%%%%%%%%%
% CONCLUSION
%%%%%%%%%%%%%%
\chapter{Conclusion}

%%%%%%%%%%%%%%%%%%
%% APPENDICES
%%%%%%%%%%%%%%%%%%
\appendix 

\chapter{Batteries output examples} \label{append:dieharder-output}
\section{Dieharder}

\begin{figure}[H]
  \begin{center}
    \includegraphics[width=12.5cm]{figures/outputs-appendix/dieharder.jpg}
  \end{center}
  \caption{Example of results table from the \emph{Dieharder} battery.}
  \label{fig:die_out}
\end{figure}

\pagebreak

\begin{figure}[H]
  \begin{center}
    \includegraphics[width=12.5cm]{figures/outputs-appendix/pvals.jpg}
  \end{center}
  \caption{Examples of first-level p-values printout from \emph{Dieharder} battery}
  \label{fig:die_pvals}
\end{figure}

\pagebreak

\section{NIST STS output} \label{append:nist-output}
\begin{figure}[H]
  \begin{center}
    \includegraphics[width=12.5cm]{figures/outputs-appendix/finalAnalysisReport.jpg}
  \end{center}
  \caption{Example of results table from the \emph{NIST STS} battery.}
  \label{fig:nist_tab}
\end{figure}

\pagebreak

\begin{figure}[H]
  \begin{center}
    \includegraphics[width=9cm]{figures/outputs-appendix/stats.jpg}
  \end{center}
  \caption{Example of p-values, test statistics and other information from NIST STS's \emph{stats.txt} file.}
  \label{fig:nist_stats}
\end{figure}

\pagebreak

\section{TestU01 output} \label{append:tu01-output}

\pagebreak

\section{FIPS battery output} \label{append:fips-output}


\begin{figure}[h]
  \begin{center}
    \includegraphics[width=10cm]{figures/outputs-appendix/fips.jpg}
  \end{center}
  \caption{Example of output from \emph{FIPS} battery.}
  \label{fig:fips_example}
\end{figure}

\section{BSI battery output} \label{append:bsi-output}


\begin{figure}[H]
  \begin{center}
    \includegraphics[width=7.5cm]{figures/outputs-appendix/bsi.jpg}
  \end{center}
  \caption{Example of output from \emph{BSI} battery.}
  \label{fig:bsi_example}
\end{figure}



\chapter{Testing Toolkits} \label{append:rtt}

\section{RTT settings} \label{append:rtt-setting}

\begin{figure}[H]
  \begin{center}
    \includegraphics[width=11cm]{figures/rtt/rtt-settings.jpg}
  \end{center}
  \caption{General settings for \emph{RTT} stored in \emph{rtt-settings.json} file.}
  \label{fig:rtt_settings}
\end{figure}



\section{RTT battery configuration} \label{append:rtt-config}

\begin{figure}[H]
  \begin{center}
    \includegraphics[width=12.5cm]{figures/rtt/config.jpg}
  \end{center}
  \caption{Example of battery configuration file for \emph{RTT}.}
  \label{fig:rtt_config}
\end{figure}



\chapter{RTT output} \label{append:rtt-output}


\chapter{rtt-py out} \label{append:rtt-py-output}
\end{document}
